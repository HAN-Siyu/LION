% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Modelling.R
\name{randomForest_RFE}
\alias{randomForest_RFE}
\title{Feature Selection Using Random Forest Classifier and Recursive Feature Elimination}
\usage{
randomForest_RFE(
  datasets = list(),
  label.col = 1,
  positive.class = NULL,
  featureNum.range = NULL,
  folds.num = 10,
  ntree = 1500,
  seed = 1,
  parallel.cores = 2,
  ...
)
}
\arguments{
\item{datasets}{should be a list containing one or several input datasets. See examples.}

\item{label.col}{an integer. The number of label column.}

\item{positive.class}{\code{NULL} or string. Which class is the positive class? Should be one
of the classes in label column. The first class in label column will be selected
as the positive class if leave \code{positive.class = NULL}.}

\item{featureNum.range}{is the range of feature number in each RFE iteration.
For example, if the original feature set has 100 features and \code{featureNum.range = c(10, 50, 80)},
20 low-ranked features will be eliminated in the first iteration, and 80 features are used to build
model in the second iteration (All features are used in the first iteration). If leave \code{NULL},
RFE will iterate five times according to feature set,
i.e. \code{c(1, 26, 50, 75, 100)} for 100-dimension feature set.}

\item{folds.num}{an integer. Number of folds. Default \code{10} for 10-fold cross validation.}

\item{ntree}{parameter for random forest. Default: 1500. See \code{\link[randomForest]{randomForest}}.}

\item{seed}{random seed for data splitting. Integer.}

\item{parallel.cores}{an integer specifying the number of cores for parallel computation. Default: \code{2}.
Set \code{parallel.cores = -1} to run with all the cores. \code{parallel.cores} should be == -1 or >= 1.}

\item{...}{other parameters passed to \code{\link[randomForest]{randomForest}} function.}
}
\value{
The function returns a list containing importance scores and relevant performance of the features.
}
\description{
Feature Selection Using Random Forest Classifier and Recursive Feature Elimination
}
\examples{

# Following codes only show how to use this function
# and cannot reflect the genuine performance of tools or classifiers.

data(demoPositiveSeq)
data(demoNegativeSeq)

RNA.positive <- demoPositiveSeq$RNA.positive
Pro.positive <- demoPositiveSeq$Pro.positive
RNA.negative <- demoNegativeSeq$RNA.negative
Pro.negative <- demoNegativeSeq$Pro.negative

dataPositive <- featureFreq(seqRNA = RNA.positive, seqPro = Pro.positive,
                            label = "Interact", featureMode = "conc",
                            computePro = "DeNovo", k.Pro = 3, k.RNA = 2,
                            normalize = "none", parallel.cores = 2)

dataNegative <- featureFreq(seqRNA = RNA.negative, seqPro = Pro.negative,
                            label = "Non.Interact", featureMode = "conc",
                            computePro = "DeNovo", k.Pro = 3, k.RNA = 2,
                            normalize = "none", parallel.cores = 2)

dataset <- rbind(dataPositive, dataNegative)

Perf_RFE <- randomForest_RFE(datasets = list(dataset), label.col = 1,
                             positive.class = "Interact",
                             featureNum.range = c(20, 50, 100),
                             folds.num = 5, ntree = 50, seed = 123,
                             parallel.cores = 2, mtry = 20)

# if you have more than one input dataset,
# use "datasets = list(dataset1, dataset2, dataset3)".

}
\seealso{
\code{\link{randomForest_CV}}, \code{\link{randomForest_tune}}, \code{\link[randomForest]{randomForest}}
}
